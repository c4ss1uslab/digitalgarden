---
{"created in":"2024-05-04T22:43:27-03:00","last tended to":"2024-11-03T15:29:05-03:00","tags":["alchemy","AI","civilizationdesign","systemschange","organization","architect","ðŸŒ±","technology","superstructure","infrastructure","metacrisis"],"relevancescore":94,"notestage":["ðŸŒ±"],"dg-publish":true,"created":"2024-05-04T22:43:27.595-03:00","updated":"2025-01-22T16:14:49.699-03:00","permalink":"/initiatives-orgs-and-communities/design/meaning-alignment-institute/","dgPassFrontmatter":true}
---

https://www.meaningalignment.org/
https://twitter.com/meaningaligned

folks in the [[concepts/design/metacrisis\|metacrisis]] space, received a grant from [[openAI\|openAI]], proposing [[tbprocessed/notion/c4ss1usâ€™ notion/50.000ft - core/knowledge management system/archive/databases/specializations/AI/AI\|AI]] dialectical/wisdom training with a methodology around harmonizing values ([[moral graphs\|moral graphs]]).

**good introductions:**

see a 5-min article introduction + link to 38-page paper: https://meaningalignment.substack.com/p/new-paper-what-are-human-values-and

1h30 video explaining the overarching vision/research basis: https://www.youtube.com/watch?v=hZpKdfbrd6osee

---
people involved: [[people/references/design/joe edelman\|joe edelman]], [[people/references/design/ellie hain\|ellie hain]], [[people/references/design/oliver klingefjord\|oliver klingefjord]]